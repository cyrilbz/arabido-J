# This file was automatically generated by BiaPy (3.6.7)

# The files scanned were these:
#     - /home/cbozonnet/miniconda3/envs/biapy-env/lib/python3.12/site-packages/biapy/models/resunet.py
#     - /home/cbozonnet/miniconda3/envs/biapy-env/lib/python3.12/site-packages/biapy/models/blocks.py


from torchvision.ops.misc import Permute
from torchvision.ops.stochastic_depth import StochasticDepth
from typing import Any, Dict, List, Optional, Tuple, Type
import torch
import torch.nn as nn
import torch.nn.functional as F

class ResUNet(nn.Module):
    """Configurable 2D/3D Residual U-Net model for image segmentation and super-resolution.

    Supports multi-head outputs and optional contrastive learning head.
    """

    def __init__(
        self,
        image_shape=(256, 256, 1),
        activation="ELU",
        feature_maps=[32, 64, 128, 256],
        drop_values=[0.1, 0.1, 0.1, 0.1],
        normalization="none",
        k_size=3,
        upsample_layer="convtranspose",
        z_down=[2, 2, 2, 2],
        output_channels=[1],
        upsampling_factor=(),
        upsampling_position="pre",
        isotropy=False,
        larger_io=True,
        contrast: bool = False,
        contrast_proj_dim: int = 256,
    ):
        """
        Create 2D/3D Residual U-Net.

        Reference: `Road Extraction by Deep Residual U-Net <https://arxiv.org/pdf/1711.10684.pdf>`_.

        Parameters
        ----------
        image_shape : 3D/4D tuple
            Dimensions of the input image. E.g. ``(y, x, channels)`` or ``(z, y, x, channels)``.

        activation : str, optional
            Activation layer.

        feature_maps : array of ints, optional
            Feature maps to use on each level.

        drop_values : float, optional
            Dropout value to be fixed.

        normalization : str, optional
            Normalization layer (one of ``'bn'``, ``'sync_bn'`` ``'in'``, ``'gn'`` or ``'none'``).

        k_size : int, optional
            Kernel size.

        upsample_layer : str, optional
            Type of layer to use to make upsampling. Two options: "convtranspose" or "upsampling".

        z_down : List of ints, optional
            Downsampling used in z dimension. Set it to ``1`` if the dataset is not isotropic.

        output_channels : list of int, optional
            Output channels of the network. It must be a list of lenght ``1`` or ``2``. When two
            numbers are provided two task to be done is expected (multi-head). Possible scenarios are:
            
                * instances + classification on instance segmentation
                * points + classification in detection.

        upsampling_factor : tuple of ints, optional
            Factor of upsampling for super resolution workflow for each dimension.

        upsampling_position : str, optional
            Whether the upsampling is going to be made previously (``pre`` option) to the model
            or after the model (``post`` option).

        isotropy : bool or list of bool, optional
            Whether to use 3d or 2d convolutions at each U-Net level even if input is 3d.

        larger_io : bool, optional
            Whether to use extra and larger kernels in the input and output layers.

        contrast : bool, optional
            Whether to add contrastive learning head to the model. Default is ``False``.

        contrast_proj_dim : int, optional
            Dimension of the projection head for contrastive learning. Default is ``256``.

        Returns
        -------
        model : Torch model
            Residual U-Net model.


        Calling this function with its default parameters returns the following network:

        .. image:: ../../img/models/unet.png
            :width: 100%
            :align: center

        Image created with `PlotNeuralNet <https://github.com/HarisIqbal88/PlotNeuralNet>`_.
        """
        super(ResUNet, self).__init__()

        if len(output_channels) == 0:
            raise ValueError("'output_channels' needs to has at least one value")
        if len(output_channels) != 1 and len(output_channels) != 2:
            raise ValueError(f"'output_channels' must be a list of one or two values at max, not {output_channels}")

        self.depth = len(feature_maps) - 1
        self.ndim = 3 if len(image_shape) == 4 else 2
        self.z_down = z_down
        self.output_channels = output_channels
        self.multihead = len(output_channels) == 2
        self.contrast = contrast
        if type(isotropy) == bool:
            isotropy = isotropy * len(feature_maps)
        if self.ndim == 3:
            conv = nn.Conv3d
            convtranspose = nn.ConvTranspose3d
            pooling = nn.MaxPool3d
            norm_func = get_norm_3d
            dropout = nn.Dropout3d
        else:
            conv = nn.Conv2d
            convtranspose = nn.ConvTranspose2d
            pooling = nn.MaxPool2d
            norm_func = get_norm_2d
            dropout = nn.Dropout3d

        # Super-resolution
        self.pre_upsampling = None
        if len(upsampling_factor) > 1 and upsampling_position == "pre":
            self.pre_upsampling = convtranspose(
                image_shape[-1],
                image_shape[-1],
                kernel_size=upsampling_factor,
                stride=upsampling_factor,
            )

        # ENCODER
        self.down_path = nn.ModuleList()
        self.mpooling_layers = nn.ModuleList()
        in_channels = image_shape[-1]

        # extra (larger) input layer
        if larger_io:
            kernel_size = (k_size + 2, k_size + 2) if self.ndim == 2 else (k_size + 2, k_size + 2, k_size + 2)
            if isotropy[0] is False and self.ndim == 3:
                kernel_size = (1, k_size + 2, k_size + 2)
            self.conv_in = ConvBlock(
                conv=conv,
                in_size=in_channels,
                out_size=feature_maps[0],
                k_size=kernel_size,
                act=activation,
                norm=normalization,
            )
            in_channels = feature_maps[0]
        else:
            self.conv_in = None

        for i in range(self.depth):
            kernel_size = (k_size, k_size) if self.ndim == 2 else (k_size, k_size, k_size)
            if isotropy[i] is False and self.ndim == 3:
                kernel_size = (1, k_size, k_size)
            self.down_path.append(
                ResConvBlock(
                    conv=conv,
                    in_size=in_channels,
                    out_size=feature_maps[i],
                    k_size=kernel_size,
                    act=activation,
                    norm=normalization,
                    dropout=drop_values[i],
                    first_block=True if i == 0 else False,
                )
            )
            mpool = (z_down[i], 2, 2) if self.ndim == 3 else (2, 2)
            self.mpooling_layers.append(pooling(mpool))
            in_channels = feature_maps[i]

        kernel_size = (k_size, k_size) if self.ndim == 2 else (k_size, k_size, k_size)
        if isotropy[-1] is False and self.ndim == 3:
            kernel_size = (1, k_size, k_size)
        self.bottleneck = ResConvBlock(
            conv=conv,
            in_size=in_channels,
            out_size=feature_maps[-1],
            k_size=kernel_size,
            act=activation,
            norm=normalization,
            dropout=drop_values[-1],
        )

        # DECODER
        self.up_path = nn.ModuleList()
        in_channels = feature_maps[-1]
        for i in range(self.depth - 1, -1, -1):
            kernel_size = (k_size, k_size) if self.ndim == 2 else (k_size, k_size, k_size)
            if isotropy[i] is False and self.ndim == 3:
                kernel_size = (1, k_size, k_size)
            self.up_path.append(
                ResUpBlock(
                    ndim=self.ndim,
                    convtranspose=convtranspose,
                    in_size=in_channels,
                    out_size=feature_maps[i],
                    in_size_bridge=feature_maps[i],
                    z_down=z_down[i],
                    up_mode=upsample_layer,
                    conv=conv,
                    k_size=kernel_size,
                    act=activation,
                    norm=normalization,
                    dropout=drop_values[i],
                )
            )
            in_channels = feature_maps[i]

        # extra (larger) output layer
        if larger_io:
            kernel_size = (k_size + 2, k_size + 2) if self.ndim == 2 else (k_size + 2, k_size + 2, k_size + 2)
            if isotropy[0] is False and self.ndim == 3:
                kernel_size = (1, k_size + 2, k_size + 2)
            self.conv_out = ConvBlock(
                conv=conv,
                in_size=feature_maps[0],
                out_size=feature_maps[0],
                k_size=kernel_size,
                act=activation,
                norm=normalization,
            )
        else:
            self.conv_out = None

        # Super-resolution
        self.post_upsampling = None
        if len(upsampling_factor) > 1 and upsampling_position == "post":
            self.post_upsampling = convtranspose(
                feature_maps[0],
                feature_maps[0],
                kernel_size=upsampling_factor,
                stride=upsampling_factor,
            )

        if self.contrast:
            # extra added layers
            self.last_block = nn.Sequential(
                conv(feature_maps[0], feature_maps[0], kernel_size=3, stride=1, padding=1),
                norm_func(normalization, feature_maps[0]),
                dropout(0.10),
                conv(feature_maps[0], output_channels[0], kernel_size=1, stride=1, padding=0, bias=False),
            )

            self.proj_head = ProjectionHead(ndim=self.ndim, in_channels=feature_maps[0], proj_dim=contrast_proj_dim)
        else:
            self.last_block = conv(feature_maps[0], output_channels[0], kernel_size=1, padding="same")

        # Multi-head:
        #   Instance segmentation: instances + classification
        #   Detection: points + classification
        self.last_class_head = None
        if self.multihead:
            self.last_class_head = conv(feature_maps[0], output_channels[1], kernel_size=1, padding="same")

        self.apply(self._init_weights)

    def forward(self, x) -> Dict | torch.Tensor:
        """Forward pass of the Residual U-Net model.

        Parameters
        ----------
        x : torch.Tensor
            Input tensor of shape (batch, channels, ...).

        Returns
        -------
        Dict or torch.Tensor
            Model output. Returns a dictionary if multi-head or contrastive outputs are enabled,
            otherwise returns the main prediction tensor.
        """
        # Super-resolution
        if self.pre_upsampling:
            x = self.pre_upsampling(x)

        # extra large-kernel input layer
        if self.conv_in:
            x = self.conv_in(x)

        # Down
        blocks = []
        for i, layers in enumerate(zip(self.down_path, self.mpooling_layers)):
            down, pool = layers
            x = down(x)
            if i != len(self.down_path):
                blocks.append(x)
                x = pool(x)

        x = self.bottleneck(x)

        # Up
        for i, up in enumerate(self.up_path):
            x = up(x, blocks[-i - 1])

        # extra large-kernel output layer
        if self.conv_out:
            x = self.conv_out(x)

        feats = x
        # Super-resolution
        if self.post_upsampling:
            feats = self.post_upsampling(feats)

        # Regular output
        out = self.last_block(feats)
        out_dict = {
            "pred": out,
        }

        # Contrastive learning head
        if self.contrast:
            out_dict["embed"] = self.proj_head(feats)

        # Multi-head output
        #   Instance segmentation: instances + classification
        #   Detection: points + classification
        if self.multihead and self.last_class_head:
            out_dict["class"] = self.last_class_head(feats)

        if len(out_dict.keys()) == 1:
            return out_dict["pred"]
        else:
            return out_dict

    def _init_weights(self, m):
        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Conv3d):
            nn.init.xavier_uniform_(m.weight)
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.Linear):
            nn.init.xavier_uniform_(m.weight)
            if isinstance(m, nn.Linear) and m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.LayerNorm):
            nn.init.constant_(m.bias, 0)
            nn.init.constant_(m.weight, 1.0)


class ProjectionHead(nn.Module):
    """
    Implements a projection head for self-supervised learning, designed to project input features into a lower-dimensional space and normalize the output.

    This module can configure its projection layer to be either a simple linear
    layer or a convolutional MLP (Multi-Layer Perceptron) structure, and supports
    different normalization types.

    Parameters
    ----------
    ndim : int
        Number of dimensions of the input data. Supports 2 (for 2D data) or 3 (for 3D data).
    in_channels : int
        Number of input feature channels.
    proj_dim : int, optional
        The desired dimension of the projected output features. Defaults to 256.
    proj : str, optional
        Specifies the type of projection layer to use.

        - 'linear': Uses a single 1x1 convolutional layer (equivalent to a linear projection).
        - 'convmlp': Employs a convolutional MLP structure, consisting of a 1x1 convolution, batch normalization, ReLU activation, and another 1x1 convolution.
        
        Defaults to 'convmlp'.
    bn_type : str, optional
        Defines the type of batch normalization to apply within the 'convmlp' projection.

        - 'sync_bn': Synchronized Batch Normalization.
        - 'none': No batch normalization is applied.
        
        Defaults to 'sync_bn'.
    """

    def __init__(self, ndim, in_channels, proj_dim=256, proj="convmlp", bn_type="sync_bn"):
        """
        Initialize the ProjectionHead module with specified dimensions, input channels, projection type, and normalization settings.

        The appropriate convolutional and normalization functions (2D or 3D) are selected
        based on the `ndim` parameter.

        Parameters
        ----------
        ndim : int
            Number of dimensions of the input data (2 for 2D, 3 for 3D).
        in_channels : int
            Number of input channels for the projection head.
        proj_dim : int, optional
            Dimension of the projected output. Defaults to 256.
        proj : str, optional
            Type of projection to use. Options are 'linear' or 'convmlp'.
            'linear' uses a simple 1x1 convolution. 'convmlp' uses a sequence of
            convolution, batch normalization, ReLU, and another convolution.
            Defaults to 'convmlp'.
        bn_type : str, optional
            Type of batch normalization to use if `proj` is 'convmlp'.
            Options are 'sync_bn' or 'none'. Defaults to 'sync_bn'.
        """
        super(ProjectionHead, self).__init__()
        self.ndim = ndim
        if self.ndim == 3:
            self.conv_call = nn.Conv3d
            self.norm_func = get_norm_3d
        else:
            self.conv_call = nn.Conv2d
            self.norm_func = get_norm_2d

        if proj == "linear":
            self.proj = self.conv_call(in_channels, proj_dim, kernel_size=1)
        elif proj == "convmlp":
            self.proj = nn.Sequential(
                self.conv_call(in_channels, in_channels, kernel_size=1),
                self.norm_func(bn_type, in_channels),
                nn.ReLU(inplace=True),
                self.conv_call(in_channels, proj_dim, kernel_size=1),
            )

    def forward(self, x):
        """
        Perform the forward pass through the projection head.

        The input tensor `x` is first passed through the configured projection layer,
        and then the output is L2-normalized along the channel dimension.

        Parameters
        ----------
        x : torch.Tensor
            The input feature tensor. Its shape should be (batch_size, in_channels, D, H, W)
            for 3D data or (batch_size, in_channels, H, W) for 2D data.

        Returns
        -------
        torch.Tensor
            The L2-normalized projected output tensor. Its shape will be
            (batch_size, proj_dim, D, H, W) or (batch_size, proj_dim, H, W),
            depending on `ndim`.
        """
        return F.normalize(self.proj(x), p=2, dim=1)


def get_norm_2d(norm: str, out_channels: int, bn_momentum: float = 0.1) -> nn.Module:
    """
    Get the specified normalization layer for a 2D model.

    Code adapted from Pytorch for Connectomics:
        `<https://github.com/zudi-lin/pytorch_connectomics/blob/6fbd5457463ae178ecd93b2946212871e9c617ee/connectomics/model/utils/misc.py#L330-L408>`_.

    Args:
        norm (str): one of ``'bn'``, ``'sync_bn'`` ``'in'``, ``'gn'`` or ``'none'``.
        out_channels (int): channel number.
        bn_momentum (float): the momentum of normalization layers.
    Returns:
        nn.Module: the normalization layer
    """
    assert norm in [
        "bn",
        "sync_bn",
        "gn",
        "in",
        "none",
    ], "Get unknown normalization layer key {}".format(norm)
    selected_norm = {
        "bn": nn.BatchNorm2d,
        "sync_bn": nn.SyncBatchNorm,
        "in": nn.InstanceNorm2d,
        "gn": lambda channels: nn.GroupNorm(16, channels),
        "none": nn.Identity,
    }[norm]
    if norm in ["bn", "sync_bn", "in"]:
        return selected_norm(out_channels, momentum=bn_momentum)
    else:
        return selected_norm(out_channels)




def get_norm_3d(norm: str, out_channels: int, bn_momentum: float = 0.1) -> nn.Module:
    """
    Get the specified normalization layer for a 3D model.

    Code adapted from Pytorch for Connectomics:
        `<https://github.com/zudi-lin/pytorch_connectomics/blob/6fbd5457463ae178ecd93b2946212871e9c617ee/connectomics/model/utils/misc.py#L330-L408>`_.

    Args:
        norm (str): one of ``'bn'``, ``'sync_bn'`` ``'in'``, ``'gn'`` or ``'none'``.
        out_channels (int): channel number.
        bn_momentum (float): the momentum of normalization layers.
    Returns:
        nn.Module: the normalization layer
    """
    assert norm in [
        "bn",
        "sync_bn",
        "gn",
        "in",
        "none",
    ], "Get unknown normalization layer key {}".format(norm)
    if norm == "gn":
        assert out_channels % 8 == 0, "GN requires channels to separable into 8 groups"
    selected_norm = {
        "bn": nn.BatchNorm3d,
        "sync_bn": nn.SyncBatchNorm,
        "in": nn.InstanceNorm3d,
        "gn": lambda channels: nn.GroupNorm(8, channels),
        "none": nn.Identity,
    }[norm]
    if norm in ["bn", "sync_bn", "in"]:
        return selected_norm(out_channels, momentum=bn_momentum)
    else:
        return selected_norm(out_channels)




class ConvBlock(nn.Module):
    """
    Implements a standard Convolutional Block.

    This block consists of a convolutional layer followed by optional
    normalization, activation, dropout, and a Squeeze-and-Excitation (SE) block.
    It serves as a versatile building component in various convolutional
    neural network architectures.
    """

    def __init__(
        self,
        conv,
        in_size,
        out_size,
        k_size,
        padding: int | str = "same",
        stride=1,
        bias=True,
        act=None,
        norm="none",
        dropout=0,
        se_block=False,
    ):
        """
        Initialize the Convolutional Block.

        Sets up the core convolutional layer along with configurable
        normalization, activation, dropout, and an optional Squeeze-and-Excitation block.

        Parameters
        ----------
        conv : Type[nn.Conv2d | nn.Conv3d]
            The convolutional layer type to use (e.g., `nn.Conv2d` for 2D, `nn.Conv3d` for 3D).
        in_size : int
            Number of input feature channels.
        out_size : int
            Number of output feature channels.
        k_size : int or tuple
            Kernel size for the convolutional layer.
        padding : int or str, optional
            Padding type for the convolutional layer. Can be an integer or "same".
            If "same", padding is calculated to maintain output spatial dimensions.
            Defaults to "same".
        stride : int or tuple, optional
            Stride for the convolutional layer. Defaults to 1.
        bias : bool, optional
            Whether to include a bias term in the convolutional layer. Defaults to `True`.
        act : Optional[str], optional
            Activation layer to use after normalization. E.g., "relu", "gelu".
            If `None`, no activation is applied. Defaults to `None`.
        norm : str, optional
            Normalization layer type to use after convolution.
            Options include `'bn'` (BatchNorm), `'sync_bn'` (SyncBatchNorm),
            `'in'` (InstanceNorm), `'gn'` (GroupNorm), or `'none'` (no normalization).
            Defaults to "none".
        dropout : float, optional
            Dropout probability to apply after activation (if any). If 0, no dropout.
            Defaults to 0.
        se_block : bool, optional
            Whether to add a Squeeze-and-Excitation (`SqExBlock`) after all other
            operations in the block. Defaults to `False`.
        """
        super(ConvBlock, self).__init__()
        block = []

        block.append(conv(in_size, out_size, kernel_size=k_size, padding=padding, stride=stride, bias=bias))
        if norm != "none":
            if conv == nn.Conv2d:
                block.append(get_norm_2d(norm, out_size))
            else:
                block.append(get_norm_3d(norm, out_size))
        if act:
            block.append(get_activation(act))
        if dropout > 0:
            block.append(nn.Dropout(dropout))
        if se_block:
            block.append(SqExBlock(out_size, ndim=2 if conv == nn.Conv2d else 3))

        self.block = nn.Sequential(*block)

    def forward(self, x):
        """
        Perform the forward pass of the Convolutional Block.

        Processes the input tensor sequentially through the defined layers:
        convolution, optional normalization, optional activation, optional dropout,
        and optional Squeeze-and-Excitation.

        Parameters
        ----------
        x : torch.Tensor
            The input feature tensor.
            Expected shape for 2D: (batch_size, in_size, height, width).
            Expected shape for 3D: (batch_size, in_size, depth, height, width).

        Returns
        -------
        torch.Tensor
            The output tensor after passing through the block.
            Its shape will be (batch_size, out_size, H', W') or (batch_size, out_size, D', H', W'),
            where H', W' (and D') depend on `padding` and `stride`.
        """
        out = self.block(x)
        return out




class ResConvBlock(nn.Module):
    """
    Implements a Residual Convolutional Block.

    This block is a core component often used in U-Net-like architectures to build
    encoder and decoder paths. It consists of a sequence of convolutional layers
    with a skip connection, allowing for better gradient flow and feature reuse.
    It supports optional pre-activation, Squeeze-and-Excitation blocks, and
    an initial extra convolutional layer.
    """

    def __init__(
        self,
        conv,
        in_size,
        out_size,
        k_size,
        act=None,
        norm="none",
        dropout=0,
        skip_k_size=1,
        skip_norm="none",
        first_block=False,
        se_block=False,
        extra_conv=False,
    ):
        """
        Initialize a Residual Convolutional Block.

        This block is a core component often used in U-Net-like architectures to build
        encoder and decoder paths. It consists of a sequence of convolutional layers
        with a skip connection, allowing for better gradient flow and feature reuse.
        It supports optional pre-activation, Squeeze-and-Excitation blocks, and
        an initial extra convolutional layer.

        Parameters
        ----------
        conv : Type[nn.Conv2d | nn.Conv3d]
            The convolutional layer type to use (e.g., `nn.Conv2d` for 2D, `nn.Conv3d` for 3D).
        in_size : int
            Number of input feature channels to the block.
        out_size : int
            Number of output feature channels for the convolutional layers within the block.
        k_size : int or tuple
            Kernel size for the main convolutional layers within the block.
        act : Optional[str], optional
            Activation layer to use after the first main convolution.
            If `None`, no activation is applied. Defaults to `None`.
        norm : str, optional
            Normalization layer type to use within the `ConvBlock` components.
            Options include `'bn'` (BatchNorm), `'sync_bn'` (SyncBatchNorm),
            `'in'` (InstanceNorm), `'gn'` (GroupNorm), or `'none'` (no normalization).
            Defaults to "none".
        dropout : float, optional
            Dropout value to be fixed within the `ConvBlock` components.
            If 0, no dropout is applied. Defaults to 0.
        skip_k_size : int, optional
            Kernel size for the convolution in the skip connection path.
            Used to adjust channel dimensions if `in_size` and `out_size` differ
            or to ensure correct output shape. Defaults to 1.
        skip_norm : str, optional
            Normalization layer type to use in the skip connection path.
            Options are `'bn'`, `'sync_bn'`, `'in'`, `'gn'`, or `'none'`.
            Defaults to "none".
        first_block : bool, optional
            If `True`, indicates that this is the first residual block in a sequence,
            which affects the application of Full Pre-Activation layers (normalization
            and activation are not applied before the first convolution in this case).
            Defaults to `False`.
            Reference: `Identity Mappings in Deep Residual Networks <https://arxiv.org/pdf/1603.05027.pdf>`_.
        se_block : bool, optional
            Whether to add a Squeeze-and-Excitation (SE) block at the end of the full
            residual block. Defaults to `False`.
        extra_conv : bool, optional
            If `True`, adds an additional convolutional layer with pre-activation
            before the main residual path, as described in Kisuk et al, 2017.
            Reference: `https://arxiv.org/pdf/1706.00120`. Defaults to `False`.
        """
        super(ResConvBlock, self).__init__()
        block = []
        pre_conv = []
        if not first_block:
            if not extra_conv:
                if norm != "none":
                    if conv == nn.Conv2d:
                        block.append(get_norm_2d(norm, in_size))
                    else:
                        block.append(get_norm_3d(norm, in_size))
                if act is not None:
                    block.append(get_activation(act))
            else:
                if norm != "none":
                    if conv == nn.Conv2d:
                        pre_conv.append(get_norm_2d(norm, in_size))
                    else:
                        pre_conv.append(get_norm_3d(norm, in_size))
                if act is not None:
                    pre_conv.append(get_activation(act))
        if extra_conv:
            pre_conv.append(
                ConvBlock(
                    conv=conv,
                    in_size=in_size,
                    out_size=out_size,
                    k_size=k_size,
                    act=act,
                    norm=norm,
                    dropout=dropout,
                )
            )
            in_size = out_size
            self.pre_conv = nn.Sequential(*pre_conv)
        else:
            self.pre_conv = None

        block.append(
            ConvBlock(
                conv=conv,
                in_size=in_size,
                out_size=out_size,
                k_size=k_size,
                act=act,
                norm=norm,
                dropout=dropout,
            )
        )
        block.append(ConvBlock(conv=conv, in_size=out_size, out_size=out_size, k_size=k_size))

        self.block = nn.Sequential(*block)

        if not extra_conv:
            block = []
            block.append(conv(in_size, out_size, kernel_size=skip_k_size, padding="same"))
            if skip_norm != "none":
                if conv == nn.Conv2d:
                    block.append(get_norm_2d(skip_norm, out_size))
                else:
                    block.append(get_norm_3d(skip_norm, out_size))
            self.shortcut = nn.Sequential(*block)
        else:
            self.shortcut = nn.Identity()

        if se_block:
            # add the Squeeze-and-Excitation block at the end of the full block (as in PyTC)
            # (https://github.com/zudi-lin/pytorch_connectomics/blob/master/connectomics/model/block/residual.py#L147-L155)
            self.se_block = SqExBlock(out_size, ndim=2 if conv == nn.Conv2d else 3)
        else:
            self.se_block = nn.Identity()

    def forward(self, x):
        """
        Perform the forward pass through the Residual Convolutional Block.

        Processes the input tensor through an optional pre-convolutional layer,
        then through the main convolutional blocks, and finally adds a skip
        connection. An optional Squeeze-and-Excitation block is applied at the end.

        Parameters
        ----------
        x : torch.Tensor
            The input feature tensor. Its shape should be (batch_size, in_size, D, H, W)
            or (batch_size, in_size, H, W).

        Returns
        -------
        torch.Tensor
            The output tensor after processing through the residual block.
            Its shape will be (batch_size, out_size, D', H', W') or
            (batch_size, out_size, H', W'), where D', H', W' match the input
            spatial dimensions if `padding="same"` is used.
        """
        if self.pre_conv is not None:
            x = self.pre_conv(x)
        out = self.block(x) + self.shortcut(x)
        return self.se_block(out)




class ResUpBlock(nn.Module):
    """
    Implements a Residual Upsampling block, typically used in the decoder path of U-Net-like architectures.

    This block performs an upsampling operation on the input feature map, concatenates it
    with a corresponding skip connection (bridge) from the encoder path, and then
    processes the combined features through a `ResConvBlock`. It supports different
    upsampling modes and integrates residual connections for improved feature propagation.

    Parameters
    ----------
    ndim : int
        Number of dimensions of the input data (2 for 2D, 3 for 3D).
    convtranspose : Type[nn.ConvTranspose2d | nn.ConvTranspose3d]
        The transpose convolutional layer type to use if `up_mode` is 'convtranspose'.
    in_size : int
        Number of input channels to the upsampling operation (from the previous decoder stage).
    out_size : int
        Number of output channels for the final `ResConvBlock` in this upsampling stage.
    in_size_bridge : int
        Number of channels of the skip connection (bridge) tensor from the encoder path.
    z_down : int, optional
        Downsampling factor applied in the z-dimension for 3D data during upsampling.
        Only relevant if `ndim` is 3. Defaults to 2.
    up_mode : str
        The upsampling mode to use.

        - 'convtranspose': Uses a transpose convolution (`convtranspose`) for upsampling.
        - 'upsampling': Uses `nn.Upsample` (bilinear for 2D, trilinear for 3D) followed by a 1x1 convolution.

    conv : Type[nn.Conv2d | nn.Conv3d]
        The convolutional layer type to use within the internal `ResConvBlock`.
    k_size : int or tuple
        Kernel size for the convolutional layers within the `ResConvBlock`.
    act : str, optional
        Activation function to use within the `ResConvBlock`. Defaults to `None`.
    norm : str, optional
        Normalization layer type to use within the `ResConvBlock`.
        Options include `'bn'`, `'sync_bn'`, `'in'`, `'gn'`, or `'none'`.
        Defaults to "none".
    skip_k_size : int, optional
        Kernel size for the skip connection convolution within the `ResConvBlock`.
        Used in ResUNet++. Defaults to 1.
    skip_norm : str, optional
        Normalization layer type for the skip connection within the `ResConvBlock`.
        Defaults to "none".
    dropout : float, optional
        Dropout value to be fixed within the `ResConvBlock`. Defaults to 0.
    se_block : bool, optional
        Whether to add Squeeze-and-Excitation blocks within the `ResConvBlock`.
        Defaults to `False`.
    extra_conv : bool, optional
        Whether to add an extra convolutional layer before the residual block
        within the `ResConvBlock` (as in Kisuk et al, 2017). Defaults to `False`.
    """
    
    def __init__(
        self,
        ndim,
        convtranspose,
        in_size,
        out_size,
        in_size_bridge,
        z_down,
        up_mode,
        conv,
        k_size,
        act=None,
        norm="none",
        skip_k_size=1,
        skip_norm="none",
        dropout=0,
        se_block=False,
        extra_conv=False,
    ):
        """
        Initialize a Residual Upsampling block, typically used in the decoder path of U-Net-like architectures.

        This block performs an upsampling operation on the input feature map, concatenates it
        with a corresponding skip connection (bridge) from the encoder path, and then
        processes the combined features through a `ResConvBlock`. It supports different
        upsampling modes and integrates residual connections for improved feature propagation.

        Parameters
        ----------
        ndim : int
            Number of dimensions of the input data (2 for 2D, 3 for 3D).
        convtranspose : Type[nn.ConvTranspose2d | nn.ConvTranspose3d]
            The transpose convolutional layer type to use if `up_mode` is 'convtranspose'.
        in_size : int
            Number of input channels to the upsampling operation (from the previous decoder stage).
        out_size : int
            Number of output channels for the final `ResConvBlock` in this upsampling stage.
        in_size_bridge : int
            Number of channels of the skip connection (bridge) tensor from the encoder path.
        z_down : int, optional
            Downsampling factor applied in the z-dimension for 3D data during upsampling.
            Only relevant if `ndim` is 3. Defaults to 2.
        up_mode : str
            The upsampling mode to use.

            - 'convtranspose': Uses a transpose convolution (`convtranspose`) for upsampling.
            - 'upsampling': Uses `nn.Upsample` (bilinear for 2D, trilinear for 3D) followed by a 1x1 convolution.
        conv : Type[nn.Conv2d | nn.Conv3d]

            The convolutional layer type to use within the internal `ResConvBlock`.
        k_size : int or tuple
            Kernel size for the convolutional layers within the `ResConvBlock`.
        act : str, optional
            Activation function to use within the `ResConvBlock`. Defaults to `None`.
        norm : str, optional
            Normalization layer type to use within the `ResConvBlock`.
            Options include `'bn'`, `'sync_bn'`, `'in'`, `'gn'`, or `'none'`.
            Defaults to "none".
        skip_k_size : int, optional
            Kernel size for the skip connection convolution within the `ResConvBlock`.
            Used in ResUNet++. Defaults to 1.
        skip_norm : str, optional
            Normalization layer type for the skip connection within the `ResConvBlock`.
            Defaults to "none".
        dropout : float, optional
            Dropout value to be fixed within the `ResConvBlock`. Defaults to 0.
        se_block : bool, optional
            Whether to add Squeeze-and-Excitation blocks within the `ResConvBlock`.
            Defaults to `False`.
        extra_conv : bool, optional
            Whether to add an extra convolutional layer before the residual block
            within the `ResConvBlock` (as in Kisuk et al, 2017). Defaults to `False`.
        """
        super(ResUpBlock, self).__init__()
        self.ndim = ndim
        mpool = (z_down, 2, 2) if ndim == 3 else (2, 2)
        if up_mode == "convtranspose":
            self.up = convtranspose(in_size, in_size, kernel_size=mpool, stride=mpool)
        elif up_mode == "upsampling":
            self.up = nn.Upsample(mode="bilinear" if ndim == 2 else "trilinear", scale_factor=mpool)

        self.conv_block = ResConvBlock(
            conv=conv,
            in_size=in_size + in_size_bridge,
            out_size=out_size,
            k_size=k_size,
            act=act,
            norm=norm,
            dropout=dropout,
            skip_k_size=skip_k_size,
            skip_norm=skip_norm,
            se_block=se_block,
            extra_conv=extra_conv,
        )

    def forward(self, x, bridge):
        """
        Perform the forward pass of the Residual Upsampling block.

        First, it upsamples the input tensor `x`. Then, it concatenates the upsampled
        tensor with the `bridge` tensor (skip connection) along the channel dimension.
        Finally, the combined tensor is passed through a `ResConvBlock`.

        Parameters
        ----------
        x : torch.Tensor
            The input feature tensor from the previous decoder stage.
            Expected shape: (batch_size, in_size, D, H, W) or (batch_size, in_size, H, W).
        bridge : torch.Tensor
            The skip connection tensor from the corresponding encoder stage.
            Expected shape: (batch_size, in_size_bridge, D', H', W'), where D', H', W'
            match the spatial dimensions after upsampling `x`.

        Returns
        -------
        torch.Tensor
            The output tensor of the upsampling block. Its shape will be
            (batch_size, out_size, D', H', W') or (batch_size, out_size, H', W'),
            where D', H', W' are the upsampled spatial dimensions.
        """
        up = self.up(x)
        out = torch.cat([up, bridge], 1)
        out = self.conv_block(out)
        return out




class SqExBlock(nn.Module):
    """
    Implements the Squeeze-and-Excitation (SE) block, a computational unit that adaptively recalibrates channel-wise feature responses.

    This block enhances the representational power of a network by explicitly
    modeling interdependencies between channels, allowing the network to
    perform feature recalibration.

    Reference: `Squeeze and Excitation Networks <https://arxiv.org/abs/1709.01507>`_.
    Credits: https://github.com/moskomule/senet.pytorch/blob/master/senet/se_module.py#L4
    """

    def __init__(self, c, r=16, ndim=2):
        """
        Initialize the Squeeze-and-Excitation block.

        Sets up the squeeze operation (global average pooling) and the excitation
        operation (two fully connected layers with ReLU and Sigmoid activations).

        Parameters
        ----------
        c : int
            Number of input channels to the block.
        r : int, optional
            Reduction ratio for the number of channels in the excitation branch.
            The hidden dimension will be `c // r`. Defaults to 16.
        ndim : int, optional
            Number of dimensions of the input data.
            Use 2 for 2D data (e.g., images) which implies `nn.AdaptiveAvgPool2d`.
            Use 3 for 3D data (e.g., volumetric scans) which implies `nn.AdaptiveAvgPool3d`.
            Defaults to 2.
        """
        super().__init__()
        self.ndim = ndim
        self.squeeze = nn.AdaptiveAvgPool2d(1) if ndim == 2 else nn.AdaptiveAvgPool3d(1)
        self.excitation = nn.Sequential(
            nn.Linear(c, c // r, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(c // r, c, bias=False),
            nn.Sigmoid(),
        )

    def forward(self, x):
        """
        Perform the forward pass of the Squeeze-and-Excitation block.

        Applies a global average pooling (squeeze) to the input to aggregate
        spatial information into a channel descriptor. This descriptor is then
        passed through a fully connected excitation network to predict
        channel-wise attention weights. Finally, these weights are applied
        to the input feature map by channel-wise multiplication.

        Parameters
        ----------
        x : torch.Tensor
            The input feature tensor.
            Expected shape for 2D: (batch_size, channels, height, width).
            Expected shape for 3D: (batch_size, channels, depth, height, width).

        Returns
        -------
        torch.Tensor
            The recalibrated feature tensor, with the same shape as the input `x`.
        """
        bs = x.shape[0]
        c = x.shape[1]
        y = self.squeeze(x).view(bs, c)
        y = self.excitation(y)
        if self.ndim == 2:
            y = y.view(bs, c, 1, 1)
        else:
            y = y.view(bs, c, 1, 1, 1)
        return x * y.expand_as(x)




def get_activation(activation: str = "relu") -> nn.Module:
    """
    Get the specified activation layer.

    Parameters
    ----------
    activation : str, optional
        One of ``'relu'``, ``'tanh'``, ``'leaky_relu'``, ``'elu'``, ``'gelu'``,
        ``'silu'``, ``'sigmoid'``, ``'softmax'``,``'swish'``, 'efficient_swish'``,
        ``'linear'``, ``'softplus'`` and ``'none'``.
    """
    assert activation in [
        "relu",
        "tanh",
        "leaky_relu",
        "elu",
        "gelu",
        "silu",
        "sigmoid",
        "softmax",
        "linear",
        "softplus",
        "none",
    ], "Get unknown activation key {}".format(activation)
    activation_dict = {
        "relu": nn.ReLU(),
        "tanh": nn.Tanh(),
        "leaky_relu": nn.LeakyReLU(negative_slope=0.2),
        "elu": nn.ELU(alpha=1.0),
        "gelu": nn.GELU(),
        "silu": nn.SiLU(),
        "sigmoid": nn.Sigmoid(),
        "softmax": nn.Softmax(dim=1),
        "linear": nn.Identity(),
        "softplus": nn.Softplus(),
        "none": nn.Identity(),
    }
    return activation_dict[activation]




